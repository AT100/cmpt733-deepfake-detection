{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c pytorch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install keras==2.1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.3.4-cp36-cp36m-macosx_10_9_x86_64.whl (8.5 MB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/dugongzzz/opt/anaconda3/envs/conda36env/lib/python3.6/site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/dugongzzz/opt/anaconda3/envs/conda36env/lib/python3.6/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/dugongzzz/opt/anaconda3/envs/conda36env/lib/python3.6/site-packages (from matplotlib) (1.19.2)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.3.1-cp36-cp36m-macosx_10_9_x86_64.whl (61 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/dugongzzz/opt/anaconda3/envs/conda36env/lib/python3.6/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six in /Users/dugongzzz/opt/anaconda3/envs/conda36env/lib/python3.6/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Installing collected packages: kiwisolver, cycler, matplotlib\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lime 0.2.0.1 requires scikit-learn>=0.18, which is not installed.\n",
      "lime 0.2.0.1 requires tqdm, which is not installed.\n",
      "insightface 0.1.5 requires scikit-learn, which is not installed.\n",
      "insightface 0.1.5 requires tqdm, which is not installed.\n",
      "aif360 0.4.0 requires scikit-learn>=0.22.1, which is not installed.\u001b[0m\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import cv2\n",
    "import matplotlib.pylab as plt\n",
    "from facenet_pytorch import MTCNN\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "import tarfile\n",
    "import urllib\n",
    "import urllib.request\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dugongzzz/Documents/GitHub/cmpt733-deepfake-detection\n"
     ]
    }
   ],
   "source": [
    "# change directory accordingly\n",
    "CURR_DIR = os.getcwd()\n",
    "print(CURR_DIR)\n",
    "INPUT_DIR = CURR_DIR + \"/train_sample_videos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training videos: 0\n"
     ]
    }
   ],
   "source": [
    "train_videopaths = sorted(glob(os.path.join(INPUT_DIR, \"*.mp4\")))[:300]\n",
    "print(\"Number of training videos:\", len(train_videopaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation videos: 0\n"
     ]
    }
   ],
   "source": [
    "val_videopaths = sorted(glob(os.path.join(INPUT_DIR, \"*.mp4\")))[300:]\n",
    "print(\"Number of validation videos:\", len(val_videopaths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to read the json file to separate real and fake videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = INPUT_DIR + '/metadata.json'\n",
    "label_df = pd.read_json(meta)\n",
    "label_df = label_df.iloc[0]\n",
    "labeling_dict = label_df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detector(videopaths, dir):\n",
    "    startTime = time.time()\n",
    "\n",
    "    for i in range(len(videopaths)):\n",
    "        num = str(i)\n",
    "        name = os.path.basename(videopaths[i])\n",
    "        print(labeling_dict[name])\n",
    "\n",
    "        width = 300\n",
    "        height = 300\n",
    "        dim = (width, height)\n",
    "\n",
    "        v_cap = cv2.VideoCapture(videopaths[i])\n",
    "        _, frame = v_cap.read()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        cv2.normalize(frame, frame, 0, 255, cv2.NORM_MINMAX)\n",
    "        #frame = cv2.fastNlMeansDenoisingColored(frame,None,10,10,7,21)\n",
    "\n",
    "        new_frame = Image.fromarray(frame)\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(new_frame)\n",
    "        plt.axis('off')\n",
    "\n",
    "        mtcnn = MTCNN(select_largest=False, keep_all=True, post_process=False)#select_largest=False, device='cuda')\n",
    "        test = mtcnn(new_frame)\n",
    "\n",
    "        # detect faces in the image\n",
    "        faces = mtcnn.detect(new_frame)\n",
    "\n",
    "        if test is None:\n",
    "            print(\"Unable to identify face\")\n",
    "            savepath = CURR_DIR + '/dataset/difficult_imgs/img' + num + '.jpg'\n",
    "            plt.imsave(savepath, frame)\n",
    "        else:   \n",
    "            for each in faces[0]:\n",
    "                if labeling_dict[name] == 'FAKE':\n",
    "                    each1 = each.tolist()\n",
    "                    x, y, w, h  = each1\n",
    "                    detected_face = frame[int(y):int(h), int(x):int(w)]\n",
    "                    plt.imshow(detected_face)\n",
    "                    savepath = CURR_DIR + '/dataset/' + dir + '/fake/img' + num + '.jpg'\n",
    "                    plt.imsave(savepath, detected_face)\n",
    "                else:\n",
    "                    each1 = each.tolist()\n",
    "                    x, y, w, h  = each1\n",
    "                    detected_face = frame[int(y):int(h), int(x):int(w)]\n",
    "                    plt.imshow(detected_face)\n",
    "                    savepath = CURR_DIR + '/dataset/' + dir + '/real/img' + num + '.jpg'\n",
    "                    plt.imsave(savepath, detected_face)\n",
    "\n",
    "    executionTime = (time.time() - startTime)\n",
    "    print('Execution time in seconds: ' + str(executionTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n",
      "375\n",
      "465\n",
      "721\n"
     ]
    }
   ],
   "source": [
    "#path = r'/Users/dugongzzz/Documents/GitHub/cmpt733-deepfake-detection/train_sample_videos'\n",
    "videopath = '/Users/dugongzzz/Documents'\n",
    "videopaths = glob(os.path.join(videopath, \"wtw.mp4\"))\n",
    "\n",
    "for i in range(len(videopaths)):\n",
    "    name = os.path.basename(videopaths[i])\n",
    "    pre, ext = os.path.splitext(name)\n",
    "    v_cap = cv2.VideoCapture(videopaths[i])\n",
    "    _, frame = v_cap.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    cv2.normalize(frame, frame, 0, 255, cv2.NORM_MINMAX)\n",
    "    #frame = cv2.fastNlMeansDenoisingColored(frame,None,10,10,7,21)\n",
    "\n",
    "    new_frame = Image.fromarray(frame)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(new_frame)\n",
    "    plt.axis('off')\n",
    "\n",
    "    mtcnn = MTCNN(select_largest=False, keep_all=True, post_process=False)#select_largest=False, device='cuda')\n",
    "    test = mtcnn(new_frame)\n",
    "\n",
    "    # detect faces in the image\n",
    "    faces = mtcnn.detect(new_frame)\n",
    "\n",
    "    if test is None:\n",
    "        print(\"Unable to identify face\")\n",
    "    else:\n",
    "        for each in faces[0]:\n",
    "            each1 = each.tolist()\n",
    "            x, y, w, h  = each1\n",
    "            top_left = int((int(y) + int(h))/2 - 128)\n",
    "            bottom_left = int((int(y) + int(h))/2 + 128)\n",
    "            top_right = int((int(x) + int(w))/2 - 128)\n",
    "            bottom_right = int((int(x) + int(w))/2 + 128)\n",
    "\n",
    "            print(top_left)\n",
    "            print(bottom_left)\n",
    "            print(top_right)\n",
    "            print(bottom_right)\n",
    "\n",
    "            detected_face = frame[top_left:bottom_left, top_right:bottom_right]\n",
    "            #detected_face = frame[bottom_left:bottom_right, top_right:bottom_right]\n",
    "            savepath = '/Users/dugongzzz/Downloads/fake/' + pre + '.jpg'\n",
    "            try:\n",
    "                plt.imsave(savepath, detected_face)\n",
    "                plt.cla()\n",
    "                plt.close('all')\n",
    "            except Exception:\n",
    "                plt.cla()\n",
    "                plt.close('all')\n",
    "                pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
