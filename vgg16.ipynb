{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801d3bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary layers  \n",
    "from tensorflow.keras.layers import Input, Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "input = Input(shape =(256,256,3))\n",
    "# 1st Conv Block\n",
    "\n",
    "x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(input)\n",
    "x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
    "# 2nd Conv Block\n",
    "\n",
    "x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
    "# 3rd Conv block\n",
    "\n",
    "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
    "# 4th Conv block\n",
    "\n",
    "x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
    "\n",
    "# 5th Conv block\n",
    "\n",
    "x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "# Fully connected layers\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(units = 256, activation ='relu')(x)\n",
    "x = Dense(units = 128, activation ='relu')(x)\n",
    "output = Dense(units = 2, activation ='softmax')(x)\n",
    "# creating the model\n",
    "\n",
    "model = Model (inputs=input, outputs =output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a4692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118d8d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'dataset/train_images'\n",
    "val_dir = 'dataset/val_images'\n",
    "test_dir = 'dataset/test_images'\n",
    "train_dir2 = 'train'\n",
    "\n",
    "#datagen = ImageDataGenerator(1./255)\n",
    "train_generator = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir2,\n",
    "    validation_split=0.2,\n",
    "    batch_size=64,\n",
    "    image_size=(256,256),\n",
    "    seed=123,\n",
    "    color_mode='rgb',\n",
    "    subset = 'training'\n",
    ")\n",
    "val_generator = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir2,\n",
    "    validation_split=0.2,\n",
    "    batch_size=64,\n",
    "    image_size=(256,256),\n",
    "    seed=123,\n",
    "    color_mode='rgb',\n",
    "    subset = 'validation'\n",
    ")\n",
    "print(train_generator.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bc0138",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    validation_data = val_generator,\n",
    "                    epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89d2ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "img = image.load_img('dataset/test_images/fake/df2.jpg', target_size=(256,256))\n",
    "img_1 = Image.open('dataset/test_images/fake/df2.jpg')\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis = 0)\n",
    "\n",
    "img2 = image.load_img('dataset/test_images/real/real00240.jpg', target_size=(256,256))\n",
    "img_2 = Image.open('dataset/test_images/real/real00240.jpg')\n",
    "img2 = image.img_to_array(img2)\n",
    "img2 = np.expand_dims(img2, axis = 0)\n",
    "\n",
    "classes = ['fake','real']\n",
    "\n",
    "#print(classes[np.argmax(model.predict(img))])\n",
    "#print(classes[np.argmax(model.predict(img2))])\n",
    "\n",
    "plt.imshow(img_1)\n",
    "plt.title(classes[np.argmax(model.predict(img))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec126ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_2)\n",
    "plt.title(classes[np.argmax(model.predict(img2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d38e7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(10)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dd7719",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/vgg16/vgg16_40_dropout_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b81ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36d46dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('model/vgg16/vgg16_4.h5')\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdbb108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('model/vgg16/vgg16_4.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57914fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "img = image.load_img('dataset/test_images/fake/df2.jpg',target_size=(256,256))\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img,axis=0)\n",
    "img /= 255.\n",
    "\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f577a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0992c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38501439",
   "metadata": {},
   "outputs": [],
   "source": [
    "top4_layers = [x.output for x in model.layers[:20]]\n",
    "top4_model = Model(inputs=model.input,outputs=top4_layers)\n",
    "\n",
    "pre = top4_model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452151c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = pre[0]\n",
    "print(f1.shape)\n",
    "plt.matshow(f1[0,:,:,22],cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8b03a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "# These are the names of the layers, so can have them as part of our plot\n",
    "layer_names = []\n",
    "for layer in model.layers[:20]:\n",
    "    layer_names.append(layer.name)\n",
    "\n",
    "images_per_row = 16\n",
    "\n",
    "# Now let's display our feature maps\n",
    "for layer_name, layer_activation in zip(layer_names, pre):\n",
    "    # This is the number of features in the feature map\n",
    "    n_features = layer_activation.shape[-1]\n",
    "\n",
    "    # The feature map has shape (1, size, size, n_features)\n",
    "    size = layer_activation.shape[1]\n",
    "\n",
    "    # We will tile the activation channels in this matrix\n",
    "    n_cols = n_features // images_per_row\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "\n",
    "    # We'll tile each filter into this big horizontal grid\n",
    "    for col in range(n_cols):\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0,\n",
    "                                             :, :,\n",
    "                                             col * images_per_row + row]\n",
    "            # Post-process the feature to make it visually palatable\n",
    "            channel_image -= channel_image.mean()\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size,\n",
    "                         row * size : (row + 1) * size] = channel_image\n",
    "\n",
    "    # Display the grid\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e5fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dir = 'test'\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    batch_size=64,\n",
    "    image_size=(256,256),\n",
    "    seed=123,\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "\"\"\"dataGenerator = ImageDataGenerator(rescale=1./255)\n",
    "test_gen = dataGenerator.flow_from_directory(\n",
    "            val_dir,\n",
    "            target_size=(256,256),\n",
    "            batch_size=64,\n",
    "            class_mode='categorical'\n",
    ")\"\"\"\n",
    "\n",
    "score = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03194f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
